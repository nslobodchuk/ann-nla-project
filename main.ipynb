{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8ee1d1-499f-410d-aa49-0b707e838965",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "Download from here: https://nlp.stanford.edu/data/glove.6B.zip (https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247228c7-c28c-4fd1-9fee-56c6189a481d",
   "metadata": {},
   "source": [
    "# GloVe ANN benchmark (base / queries / ground truth)\n",
    "\n",
    "This notebook loads Stanford GloVe embeddings and constructs a simple ANN benchmark for cosine (angular) similarity.\n",
    "\n",
    "- **Parsing:** the file `glove.6B.*d.txt` is parsed into a token list `words` and an embedding matrix $E \\in \\mathbb{R}^{M \\times D}$, where each row corresponds to a word vector.\n",
    "- **Base and queries:** the search base is defined as the first $N$ vectors $X \\in \\mathbb{R}^{N \\times D}$, and the query set is formed by sampling a random subset of rows from $X$ using indices $q_{\\text{idx}}$: $Q = X[q_{\\text{idx}}] \\in \\mathbb{R}^{n_q \\times D}$.\n",
    "- **Cosine / angular setting:** vectors are L2-normalized $X_n = \\frac{X}{\\|X\\|_2}$ and $Q_n = \\frac{Q}{\\|Q\\|_2}$, so cosine similarity reduces to a dot product $s(q, x) = \\frac{q^\\top x}{\\|q\\|_2\\|x\\|_2} = q_n^\\top x_n$.\n",
    "- **Ground truth (exact top-$k$):** exact neighbors are computed via batched matrix multiplication $S = Q_n X_n^\\top$, excluding the trivial self-match (since queries are drawn from the base). The benchmark stores $\\text{gt\\_ids} \\in \\mathbb{N}^{n_q \\times k}$ (top-$k$ neighbor indices) and $\\text{gt\\_scores} \\in \\mathbb{R}^{n_q \\times k}$ (corresponding cosine similarity values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed91ac76-7eab-43c1-b4a8-2ecba05c846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xn: (100000, 50) Qn: (10000, 50) gt_ids: (10000, 10)\n",
      "Example query word: gleaner\n",
      "Top neighbors: ['suara', 'telegraaf', 'prensa', 'jornal', 'andina', 'marca', 'republica', 'expresso', 'folha', 'ouest']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def load_glove(path: str) -> Tuple[List[str], np.ndarray]:\n",
    "    words: List[str] = []\n",
    "    embeddings: List[List[float]] = []\n",
    "    dim: int | None = None\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            p = line.split()\n",
    "            if dim is None:\n",
    "                dim = len(p) - 1\n",
    "            words.append(p[0])\n",
    "            embeddings.append([float(x) for x in p[1:]])\n",
    "\n",
    "    X = np.asarray(embeddings, dtype=np.float32)\n",
    "\n",
    "    # Sanity check: all rows must have the same dimensionality.\n",
    "    if dim is not None:\n",
    "        assert X.shape[1] == dim, f\"Inconsistent embedding dimension: expected {dim}, got {X.shape[1]}\"\n",
    "\n",
    "    return words, X\n",
    "\n",
    "\n",
    "def l2_normalize(X: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X / np.maximum(n, eps)\n",
    "\n",
    "\n",
    "def make_base_and_queries(\n",
    "    words: List[str],\n",
    "    embeddings: np.ndarray,\n",
    "    N: int = 100_000,\n",
    "    nq: int = 10_000,\n",
    "    seed: int = 0,\n",
    ") -> Tuple[List[str], np.ndarray, np.ndarray]:\n",
    "    assert 0 < N <= len(words), \"N must be in (0, len(words)].\"\n",
    "    assert 0 < nq <= N, \"nq must be in (0, N].\"\n",
    "\n",
    "    base_words = words[:N]\n",
    "    X = embeddings[:N].astype(np.float32, copy=False)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    q_idx = rng.choice(N, size=nq, replace=False).astype(np.int64)\n",
    "\n",
    "    return base_words, X, q_idx\n",
    "\n",
    "\n",
    "def ground_truth_topk_cosine(\n",
    "    X: np.ndarray,\n",
    "    q_idx: np.ndarray,\n",
    "    k: int = 10,\n",
    "    x_batch: int = 5_000,\n",
    "    q_batch: int = 1_024,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    Xn = l2_normalize(X)\n",
    "    Qn = Xn[q_idx]  # Queries are sampled from the base, already normalized.\n",
    "\n",
    "    N = Xn.shape[0]\n",
    "    nq = Qn.shape[0]\n",
    "    assert 0 < k <= N, \"k must be in (0, N].\"\n",
    "\n",
    "    best_scores = np.full((nq, k), -np.inf, dtype=np.float32)\n",
    "    best_ids = np.full((nq, k), -1, dtype=np.int32)\n",
    "\n",
    "    for x0 in range(0, N, x_batch):\n",
    "        Xb = Xn[x0 : x0 + x_batch]\n",
    "        xb = Xb.shape[0]\n",
    "        kk = min(k, xb)\n",
    "\n",
    "        for q0 in range(0, nq, q_batch):\n",
    "            q1 = min(q0 + q_batch, nq)\n",
    "            Qb = Qn[q0:q1]          # (qb, D)\n",
    "            scores = Qb @ Xb.T      # (qb, xb)\n",
    "\n",
    "            # Exclude trivial self-match (query vectors are from the base).\n",
    "            q_base = q_idx[q0:q1]\n",
    "            m = (q_base >= x0) & (q_base < x0 + xb)\n",
    "            if m.any():\n",
    "                rows = np.nonzero(m)[0]\n",
    "                cols = (q_base[m] - x0).astype(np.int64)\n",
    "                scores[rows, cols] = -np.inf\n",
    "\n",
    "            idx = np.argpartition(scores, -kk, axis=1)[:, -kk:]\n",
    "            sc = np.take_along_axis(scores, idx, axis=1)\n",
    "            ids = (idx + x0).astype(np.int32)\n",
    "\n",
    "            merged_sc = np.concatenate([best_scores[q0:q1], sc], axis=1)\n",
    "            merged_ids = np.concatenate([best_ids[q0:q1], ids], axis=1)\n",
    "            sel = np.argpartition(merged_sc, -k, axis=1)[:, -k:]\n",
    "\n",
    "            best_scores[q0:q1] = np.take_along_axis(merged_sc, sel, axis=1)\n",
    "            best_ids[q0:q1] = np.take_along_axis(merged_ids, sel, axis=1)\n",
    "\n",
    "    order = np.argsort(best_scores, axis=1)[:, ::-1]\n",
    "    best_scores = np.take_along_axis(best_scores, order, axis=1)\n",
    "    best_ids = np.take_along_axis(best_ids, order, axis=1)\n",
    "\n",
    "    return Xn, Qn, best_ids, best_scores\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "words, embeddings = load_glove(\"glove.6B/glove.6B.50d.txt\")\n",
    "\n",
    "N, nq, k = 100_000, 10_000, 10\n",
    "base_words, X, q_idx = make_base_and_queries(words, embeddings, N=N, nq=nq, seed=42)\n",
    "Xn, Qn, gt_ids, gt_scores = ground_truth_topk_cosine(X, q_idx, k=k, x_batch=5_000, q_batch=1_024)\n",
    "\n",
    "print(\"Xn:\", Xn.shape, \"Qn:\", Qn.shape, \"gt_ids:\", gt_ids.shape)\n",
    "print(\"Example query word:\", base_words[q_idx[0]])\n",
    "print(\"Top neighbors:\", [base_words[i] for i in gt_ids[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
